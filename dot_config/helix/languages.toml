[language-server.lsp-ai]
command = "lsp-ai"

# [language-server.gpt]
# command = "helix-gpt"

[language-server.lsp-ai.config.memory]
file_store = {}


########## Define Models

# [language-server.lsp-ai.config.models.ollama]
# type = "ollama"
# chat_endpoint = "http://localhost:11434/api/chat"
# model = "deepseek-coder-v2"

# [language-server.lsp-ai.config.models.llama]
# type = "llama_cpp"
# repository = "stabilityai/stable-code-3b"
# name = "stable-code-3b-Q5_K_M.gguf"
# n_ctx = 2048
# n_gpu_layers = 1000

[language-server.lsp-ai.config.models.tabby]
type = "open_ai"
chat_endpoint = "http://localhost:8080/v1/chat"
auth_token = "auth_881a958cbb454e1aa87a3fa17e8e9649" 
model = "Qwen2-1.5B-Instruct"

[language-server.lsp-ai.config.models.openaimini]
type = "open_ai"
chat_endpoint = "https://api.openai.com/v1/chat/completions"
model = "gpt-4o-mini"
auth_token_env_var_name = "OPENAI_API_KEY"
max_requests_per_second = 0.3

[language-server.lsp-ai.config.models.openai]
type = "open_ai"
chat_endpoint = "https://api.openai.com/v1/chat/completions"
model = "gpt-4o"
auth_token_env_var_name = "OPENAI_API_KEY"
max_requests_per_second = 0.3

# [language-server.lsp-ai.config.models.anthropic]
# type = "anthropic"
# chat_endpoint = "https://api.anthropic.com/v1/messages"
# model = "claude-3-5-sonnet-20240620"
# auth_token_env_var_name = "ANTHROPIC_API_KEY"


########################################### Chat with openai
[[language-server.lsp-ai.config.chat]]
trigger = "!C"
action_display_name = "Chat"
model = "openai"

[language-server.lsp-ai.config.chat.parameters]
max_context = 4096
max_tokens = 1024

[[language-server.lsp-ai.config.chat.parameters.messages]]
role = "system"
content = "You are a code assistant chatbot. The user will ask you for assistance coding and you will do you best to answer succinctly and accurately."

# ######################################## Completion with openai
# [language-server.lsp-ai.config.completion]
# model = "openaimini"

# [language-server.lsp-ai.config.completion.parameters]
# max_context = 2048
# max_tokens = 200

# # [language-server.lsp-ai.config.completion.parameters.options]
# # num_predict = 32

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "system"
# content = "Instructions:\n- You are an AI programming assistant.\n- Given a piece of code with the cursor location marked by \"<CURSOR>\", replace \"<CURSOR>\" with the correct code or comment. Only respond with code or comments.\n- Only replace \"<CURSOR>\"; do not include any previously written code.\n- Never include \"<CURSOR>\" in your response\n- If the cursor is within a comment, complete the comment meaningfully.."

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "user"
# content = "def greet(name):\n    print(f\"Hello, {<CURSOR>}\")"

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "assistant"
# content = "name"

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "user"
# content = "function sum(a, b) {\n    return a + <CURSOR>;\n}"

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "assistant"
# content = "b"

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "user"
# content = "fn multiply(a: i32, b: i32) -> i32 {\n    a * <CURSOR>\n}"

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "assistant"
# content = "b"

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "user"
# content = "# <CURSOR>\ndef add(a, b):\n    return a + b"

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "assistant"
# content = "Adds two numbers"

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "user"
# content = "# This function checks if a number is even\n<CURSOR>"

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "assistant"
# content = "def is_even(n):\n    return n % 2 == 0"

# [[language-server.lsp-ai.config.completion.parameters.messages]]
# role = "user"
# content = "{CODE}"

######################################## Completion with tabby
[language-server.lsp-ai.config.completion]
model = "tabby"

[language-server.lsp-ai.config.completion.parameters]
max_context = 2048
max_tokens = 200

# [language-server.lsp-ai.config.completion.parameters.options]
# num_predict = 32

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "system"
content = "Instructions:\n- You are an AI programming assistant.\n- Given a piece of code with the cursor location marked by \"<CURSOR>\", replace \"<CURSOR>\" with the correct code or comment. Only respond with code or comments.\n- Only replace \"<CURSOR>\"; do not include any previously written code.\n- Never include \"<CURSOR>\" in your response\n- If the cursor is within a comment, complete the comment meaningfully.."

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "user"
content = "def greet(name):\n    print(f\"Hello, {<CURSOR>}\")"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "assistant"
content = "name"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "user"
content = "function sum(a, b) {\n    return a + <CURSOR>;\n}"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "assistant"
content = "b"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "user"
content = "fn multiply(a: i32, b: i32) -> i32 {\n    a * <CURSOR>\n}"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "assistant"
content = "b"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "user"
content = "# <CURSOR>\ndef add(a, b):\n    return a + b"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "assistant"
content = "Adds two numbers"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "user"
content = "# This function checks if a number is even\n<CURSOR>"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "assistant"
content = "def is_even(n):\n    return n % 2 == 0"

[[language-server.lsp-ai.config.completion.parameters.messages]]
role = "user"
content = "{CODE}"

#################################### Action Quick Complete
[[language-server.lsp-ai.config.actions]]
action_display_name = "QuickComplete"
model = "openaimini"

[language-server.lsp-ai.config.actions.parameters]
max_context = 4096
max_tokens = 4096

[language-server.lsp-ai.config.actions.post_process]
extractor = """(?s)<answer>(.*?)</answer>"""

[[language-server.lsp-ai.config.actions.parameters.messages]]
role = "user"
content = "You are a coding assistant. You provide new code that should be inserted at the user's cursor marked by \"<CURSOR>\". Analyze step by step   where the CURSOR is in the code. When you are ready, write your result for the code you want to insert, starting with \"<answer>\" and ending with \"</answer>\". Do not include the blockquotes ```python .., so that I can directly use the code."

[[language-server.lsp-ai.config.actions.parameters.messages]]
role = "user"
content = "{CODE}"

#################################### Action Complete
[[language-server.lsp-ai.config.actions]]
action_display_name = "Complete"
model = "openai"

[language-server.lsp-ai.config.actions.post_process]
extractor = """(?s)<answer>(.*?)</answer>"""

[language-server.lsp-ai.config.actions.parameters]
max_context = 4096
max_tokens = 4096
# system = """When on anthropic, fill in here"""

[[language-server.lsp-ai.config.actions.parameters.messages]]
role = "system"
content = """You are an AI coding assistant. Your task is to complete code snippets. The user's cursor position is marked by "<CURSOR>". Follow these steps:

1. Analyze the code context and the cursor position.
2. Provide your chain of thought reasoning, wrapped in <reasoning> tags. Include thoughts about the cursor position, what needs to be completed, and any necessary formatting.
3. Determine the appropriate code to complete the current thought, including finishing partial words or lines.
4. Replace "<CURSOR>" with the necessary code, ensuring proper formatting and line breaks.
5. Wrap your code solution in <answer> tags.

Your response should always include both the reasoning and the answer. Pay special attention to completing partial words or lines before adding new lines of code.

<examples>
<example>
User input:
--main.py--
# A function that reads in user inpu<CURSOR>

Response:
<reasoning>
1. The cursor is positioned after "inpu" in a comment describing a function that reads user input.
2. We need to complete the word "input" in the comment first.
3. After completing the comment, we should add a new line before defining the function.
4. The function should use Python's built-in `input()` function to read user input.
5. We'll name the function descriptively and include a return statement.
</reasoning>

<answer>t
def read_user_input():
    user_input = input("Enter your input: ")
    return user_input
</answer>
</example>

<example>
User input:
--main.py--
def fibonacci(n):
    if n <= 1:
        return n
    else:
        re<CURSOR>


Response:
<reasoning>
1. The cursor is positioned after "re" in the 'else' clause of a recursive Fibonacci function.
2. We need to complete the return statement for the recursive case.
3. The "re" already present likely stands for "return", so we'll continue from there.
4. The Fibonacci sequence is the sum of the two preceding numbers.
5. We should return the sum of fibonacci(n-1) and fibonacci(n-2).
</reasoning>

<answer>turn fibonacci(n-1) + fibonacci(n-2)</answer>
</example>
</examples>
"""

[[language-server.lsp-ai.config.actions.parameters.messages]]
role = "user"
content = "{CODE}"

###################################### Action insert
[[language-server.lsp-ai.config.actions]]
action_display_name = "SelectedInstruction"
model = "openai"

[language-server.lsp-ai.config.actions.parameters]
max_context = 4096
max_tokens = 4096

[[language-server.lsp-ai.config.actions.parameters.messages]]
role = "system"
content = "You are an coding assistant. The user cursor position is marked with <CURSOR>. You only respond with valid code with few comments. "

[[language-server.lsp-ai.config.actions.parameters.messages]]
role = "user"
content = "{CODE}"

[[language-server.lsp-ai.config.actions.parameters.messages]]
role = "user"
content = "Write code with this instruction: {SELECTED_TEXT}"

###################################### Action refactor
[[language-server.lsp-ai.config.actions]]
action_display_name = "Refactor"
model = "openai"

[language-server.lsp-ai.config.actions.post_process]
extractor = """(?s)<answer>(.*?)</answer>"""

[language-server.lsp-ai.config.actions.parameters]
max_context = 4096
max_tokens = 4096
# When on anthropic, use system = "..."

[[language-server.lsp-ai.config.actions.parameters.messages]]
role = "system"
content = """You are an AI coding assistant specializing in code refactoring. Your task is to analyze the given code snippet and provide a refactored version. Follow these steps:

1. Analyze the code context and structure.
2. Identify areas for improvement, such as code efficiency, readability, or adherence to best practices.
3. Provide your chain of thought reasoning, wrapped in <reasoning> tags. Include your analysis of the current code and explain your refactoring decisions.
4. Rewrite the entire code snippet with your refactoring applied.
5. Wrap your refactored code solution in <answer> tags.

Your response should always include both the reasoning and the refactored code.

<examples>
<example>
User input:
def calculate_total(items):
    total = 0
    for item in items:
        total = total + item['price'] * item['quantity']
    return total


Response:
<reasoning>
1. The function calculates the total cost of items based on price and quantity.
2. We can improve readability and efficiency by:
   a. Using a more descriptive variable name for the total.
   b. Utilizing the sum() function with a generator expression.
   c. Using augmented assignment (+=) if we keep the for loop.
3. We'll implement the sum() function approach for conciseness.
4. We'll add a type hint for better code documentation.
</reasoning>
<answer>
from typing import List, Dict

def calculate_total(items: List[Dict[str, float]]) -> float:
    return sum(item['price'] * item['quantity'] for item in items)
</answer>
</example>

<example>
User input:
def is_prime(n):
    if n < 2:
        return False
    for i in range(2, n):
        if n % i == 0:
            return False
    return True


Response:
<reasoning>
1. This function checks if a number is prime, but it's not efficient for large numbers.
2. We can improve it by:
   a. Adding an early return for 2, the only even prime number.
   b. Checking only odd numbers up to the square root of n.
   c. Using a more efficient range (start at 3, step by 2).
3. We'll also add a type hint for better documentation.
4. The refactored version will be more efficient for larger numbers.
</reasoning>
<answer>
import math

def is_prime(n: int) -> bool:
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False
    
    for i in range(3, int(math.sqrt(n)) + 1, 2):
        if n % i == 0:
            return False
    return True
</answer>
</example>
</examples>
"""

[[language-server.lsp-ai.config.actions.parameters.messages]]
role = "user"
content = "{SELECTED_TEXT}"

###################################################### Language definitions
[[language]]
name = "markdown"
language-servers = [
  "lsp-ai",
  # { name = "gpt", except-features = [
  #   "diagnostics",
  # ] },
]

[[language]]
name = "python"
auto-format = true
language-servers = [
  "pyright",
  "ruff",
  "lsp-ai",
  # { name = "gpt", except-features = ["diagnostics"] },
]
formatter = { command = "bash", args = [
  "-c",
  "ruff check --select I --fix - | ruff format - ",
] }

[language-server.pyright.config.python.analysis]
typeCheckingMode = "basic"

[language-server.basedpyright.analysis]
typeCheckingMode = "basic"

[language-server.ruff]
command = "ruff-lsp"

[language-server.ruff.config.settings]
args = ["--ignore", "E501"]

[[language]]
name = "toml"
auto-format = true
language-servers = ["taplo", "lsp-ai"]
formatter = { command = "taplo", args = ["fmt", "-"] }

[[language]]
name = "yaml"
file-types = ["yaml", "yml"]
auto-format = true
formatter = { command = "bash", args = ["-c", " prettier --parser yaml"] }

[[language]]
name = "docker-compose"
file-types = ["docker-compose"]
auto-format = true
formatter = { command = "bash", args = ["-c", " prettier --parser yaml"] }

[[language]]
name = "html"
file-types = ["html", "xml"]
auto-format = true
formatter = { command = "bash", args = [
  "-c",
  "prettier --stdin-filepath xx.html ",
] }

[[language]]
name = "lua"
file-types = ["lua"]
auto-format = true
language-servers = ["luals", "lsp-ai"]

[[language]]
name = "bash"
auto-format = true
language-servers = ["bash-language-server", "lsp-ai"]

[[language]]
name = "typescript"
auto-format = true
language-servers = ["typescript-language-server", "lsp-ai"]

[[language]]
name = "rust"
auto-format = true
language-servers = [
  "rust-analyzer",
  "lsp-ai",
  # { name = "gpt", except-features = [
  #   "diagnostics",
  # ] },
]

[[language]]
name = "javascript"
auto-format = true
language-servers = ["typescript-language-server", "lsp-ai"]
